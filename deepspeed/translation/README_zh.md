<!---
ç‰ˆæƒæ‰€æœ‰ 2020 HuggingFace å›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

æ ¹æ® Apache è®¸å¯è¯ 2.0 ç‰ˆï¼ˆ"è®¸å¯è¯"ï¼‰æˆæƒï¼›
é™¤éç¬¦åˆè®¸å¯è¯çš„è§„å®šï¼Œå¦åˆ™æ‚¨ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚
æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®è·å¾—è®¸å¯è¯å‰¯æœ¬

    http://www.apache.org/licenses/LICENSE-2.0

é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™è½¯ä»¶
æ ¹æ®è®¸å¯è¯åˆ†å‘æ˜¯åœ¨"æŒ‰åŸæ ·"çš„åŸºç¡€ä¸Šåˆ†å‘çš„ï¼Œ
ä¸é™„å¸¦ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„æ‹…ä¿æˆ–æ¡ä»¶ã€‚
è¯·å‚é˜…è®¸å¯è¯äº†è§£ç‰¹å®šè¯­è¨€çš„ç®¡ç†æƒé™å’Œé™åˆ¶ã€‚
-->

## ç¿»è¯‘

æ­¤ç›®å½•åŒ…å«åœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šå¾®è°ƒå’Œè¯„ä¼° transformers çš„ç¤ºä¾‹ã€‚
å¦‚æœ‰ä»»ä½•é—®é¢˜/æ„å¤–è¡Œä¸ºï¼Œè¯·æ ‡è®° @patil-suraj æˆ–å‘é€ PRï¼
æœ‰å…³å·²å¼ƒç”¨çš„ `bertabs` æŒ‡ä»¤ï¼Œè¯·å‚è§ [`bertabs/README.md`](https://github.com/huggingface/transformers/blob/main/examples/research_projects/bertabs/README.md)ã€‚
æœ‰å…³æ—§ç‰ˆ `finetune_trainer.py` å’Œç›¸å…³å·¥å…·ï¼Œè¯·å‚è§ [`examples/legacy/seq2seq`](https://github.com/huggingface/transformers/blob/main/examples/legacy/seq2seq)ã€‚

### æ”¯æŒçš„æ¶æ„

- `BartForConditionalGeneration`
- `FSMTForConditionalGeneration`ï¼ˆä»…é™ç¿»è¯‘ï¼‰
- `MBartForConditionalGeneration`
- `MarianMTModel`
- `PegasusForConditionalGeneration`
- `T5ForConditionalGeneration`
- `MT5ForConditionalGeneration`

`run_translation.py` æ˜¯ä¸€ä¸ªè½»é‡çº§ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•ä» [ğŸ¤— Datasets](https://github.com/huggingface/datasets) åº“ä¸‹è½½å’Œé¢„å¤„ç†æ•°æ®é›†ï¼Œæˆ–ä½¿ç”¨æ‚¨è‡ªå·±çš„æ–‡ä»¶ï¼ˆjsonlines æˆ– csvï¼‰ï¼Œç„¶ååœ¨ä¸Šè¿°æ¶æ„ä¹‹ä¸€ä¸Šè¿›è¡Œå¾®è°ƒã€‚

æœ‰å…³ `jsonlines` æ ¼å¼çš„è‡ªå®šä¹‰æ•°æ®é›†ï¼Œè¯·å‚è§ï¼šhttps://huggingface.co/docs/datasets/loading_datasets#json-files
æ‚¨ä¹Ÿå¯ä»¥åœ¨ä¸‹é¢æ‰¾åˆ°è¿™äº›ç¤ºä¾‹ã€‚


## ä½¿ç”¨ Trainer

ä»¥ä¸‹æ˜¯ä½¿ç”¨ MarianMT æ¨¡å‹è¿›è¡Œç¿»è¯‘å¾®è°ƒçš„ç¤ºä¾‹ï¼š

```bash
python examples/pytorch/translation/run_translation.py \
    --model_name_or_path Helsinki-NLP/opus-mt-en-ro \
    --do_train \
    --do_eval \
    --source_lang en \
    --target_lang ro \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --output_dir /tmp/tst-translation \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

MBart å’Œä¸€äº› T5 æ¨¡å‹éœ€è¦ç‰¹æ®Šå¤„ç†ã€‚

T5 æ¨¡å‹ `t5-small`ã€`t5-base`ã€`t5-large`ã€`t5-3b` å’Œ `t5-11b` å¿…é¡»ä½¿ç”¨é™„åŠ å‚æ•°ï¼š`--source_prefix "translate {source_lang} to {target_lang}"`ã€‚ä¾‹å¦‚ï¼š

```bash
python translation/run_translation.py \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --source_lang en \
    --target_lang ro \
    --source_prefix "translate English to Romanian: " \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --output_dir /tmp/tst-translation \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

å¦‚æœæ‚¨å¾—åˆ°çš„ BLEU åˆ†æ•°å¾ˆå·®ï¼Œè¯·ç¡®ä¿æ‚¨æ²¡æœ‰å¿˜è®°ä½¿ç”¨ `--source_prefix` å‚æ•°ã€‚

å¯¹äºä¸Šè¿° T5 æ¨¡å‹ç»„ï¼Œé‡è¦çš„æ˜¯è¦è®°ä½ï¼Œå¦‚æœæ‚¨åˆ‡æ¢åˆ°ä¸åŒçš„è¯­è¨€å¯¹ï¼Œè¯·ç¡®ä¿è°ƒæ•´æ‰€æœ‰ 3 ä¸ªç‰¹å®šäºè¯­è¨€çš„å‘½ä»¤è¡Œå‚æ•°ä¸­çš„æºå’Œç›®æ ‡å€¼ï¼š`--source_lang`ã€`--target_lang` å’Œ `--source_prefix`ã€‚

MBart æ¨¡å‹éœ€è¦ä¸åŒçš„ `--source_lang` å’Œ `--target_lang` å€¼æ ¼å¼ï¼Œä¾‹å¦‚ï¼Œå®ƒæœŸæœ› `en_XX` è€Œä¸æ˜¯ `en`ï¼Œå¯¹äº `ro` å®ƒæœŸæœ› `ro_RO`ã€‚MBart è¯­è¨€ä»£ç çš„å®Œæ•´è§„èŒƒå¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/facebook/mbart-large-cc25)æ‰¾åˆ°ã€‚ä¾‹å¦‚ï¼š

```bash
python examples/pytorch/translation/run_translation.py \
    --model_name_or_path facebook/mbart-large-en-ro  \
    --do_train \
    --do_eval \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --source_lang en_XX \
    --target_lang ro_RO \
    --output_dir /tmp/tst-translation \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

ä»¥ä¸‹æ˜¯æ‚¨å¦‚ä½•åœ¨è‡ªå·±çš„æ–‡ä»¶ä¸Šä½¿ç”¨ç¿»è¯‘å¾®è°ƒï¼Œåœ¨è°ƒæ•´å‚æ•° `--train_file`ã€`--validation_file` çš„å€¼ä»¥åŒ¹é…æ‚¨çš„è®¾ç½®åï¼š

```bash
python examples/pytorch/translation/run_translation.py \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --source_lang en \
    --target_lang ro \
    --source_prefix "translate English to Romanian: " \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --train_file path_to_jsonlines_file \
    --validation_file path_to_jsonlines_file \
    --output_dir /tmp/tst-translation \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

ç¿»è¯‘ä»»åŠ¡ä»…æ”¯æŒè‡ªå®šä¹‰ JSONLINES æ–‡ä»¶ï¼Œæ¯è¡Œæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸º `"translation"`ï¼Œå…¶å€¼æ˜¯å¦ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºè¯­è¨€å¯¹ã€‚ä¾‹å¦‚ï¼š

```json
{ "translation": { "en": "Others have dismissed him as a joke.", "ro": "AlÈ›ii l-au numit o glumÄƒ." } }
{ "translation": { "en": "And some are holding out for an implosion.", "ro": "Iar alÈ›ii aÈ™teaptÄƒ implozia." } }
```
è¿™é‡Œçš„è¯­è¨€æ˜¯ç½—é©¬å°¼äºšè¯­ï¼ˆ`ro`ï¼‰å’Œè‹±è¯­ï¼ˆ`en`ï¼‰ã€‚

å¦‚æœæ‚¨æƒ³ä½¿ç”¨é¢„å¤„ç†çš„æ•°æ®é›†ä»¥è·å¾—é«˜ BLEU åˆ†æ•°ï¼Œä½†é’ˆå¯¹ `en-de` è¯­è¨€å¯¹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ `--dataset_name stas/wmt14-en-de-pre-processed`ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
python examples/pytorch/translation/run_translation.py \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --source_lang en \
    --target_lang de \
    --source_prefix "translate English to German: " \
    --dataset_name stas/wmt14-en-de-pre-processed \
    --output_dir /tmp/tst-translation \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

## ä½¿ç”¨ Accelerate

åŸºäºè„šæœ¬ [`run_translation_no_trainer.py`](https://github.com/huggingface/transformers/blob/main/examples/pytorch/translation/run_translation_no_trainer.py)ã€‚

ä¸ `run_translation.py` ç±»ä¼¼ï¼Œæ­¤è„šæœ¬å…è®¸æ‚¨åœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šå¾®è°ƒä»»ä½•å—æ”¯æŒçš„æ¨¡å‹ï¼Œä¸»è¦åŒºåˆ«æ˜¯æ­¤è„šæœ¬æš´éœ²äº†è£¸è®­ç»ƒå¾ªç¯ï¼Œå…è®¸æ‚¨å¿«é€Ÿè¯•éªŒå¹¶æ·»åŠ ä»»ä½•æƒ³è¦çš„è‡ªå®šä¹‰ã€‚

å®ƒæä¾›çš„é€‰é¡¹æ¯”ä½¿ç”¨ `Trainer` çš„è„šæœ¬å°‘ï¼ˆä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨è„šæœ¬ä¸­è½»æ¾æ›´æ”¹ä¼˜åŒ–å™¨æˆ–æ•°æ®åŠ è½½å™¨çš„é€‰é¡¹ï¼‰ï¼Œä½†ä»å¯åœ¨åˆ†å¸ƒå¼è®¾ç½®ä¸­è¿è¡Œï¼Œåœ¨ TPU ä¸Šè¿è¡Œï¼Œå¹¶é€šè¿‡ [ğŸ¤— `Accelerate`](https://github.com/huggingface/accelerate) åº“æ”¯æŒæ··åˆç²¾åº¦ã€‚å®‰è£…åæ‚¨å¯ä»¥æ­£å¸¸ä½¿ç”¨è¯¥è„šæœ¬ï¼š

```bash
pip install git+https://github.com/huggingface/accelerate
```

ç„¶å

```bash
python run_translation_no_trainer.py \
    --model_name_or_path Helsinki-NLP/opus-mt-en-ro \
    --source_lang en \
    --target_lang ro \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --output_dir ~/tmp/tst-translation
```

ç„¶åæ‚¨å¯ä»¥ä½¿ç”¨å¸¸ç”¨çš„å¯åŠ¨å™¨åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è¿è¡Œå®ƒï¼Œä½†æœ€ç®€å•çš„æ–¹æ³•æ˜¯è¿è¡Œ

```bash
accelerate config
```

å¹¶å›ç­”æå‡ºçš„é—®é¢˜ã€‚ç„¶å

```bash
accelerate test
```

è¿™å°†æ£€æŸ¥è®­ç»ƒæ‰€éœ€çš„ä¸€åˆ‡æ˜¯å¦å·²å‡†å¤‡å°±ç»ªã€‚æœ€åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è®­ç»ƒï¼š

```bash
accelerate launch run_translation_no_trainer.py \
    --model_name_or_path Helsinki-NLP/opus-mt-en-ro \
    --source_lang en \
    --target_lang ro \
    --dataset_name wmt16 \
    --dataset_config_name ro-en \
    --output_dir ~/tmp/tst-translation
```

æ­¤å‘½ä»¤æ˜¯ç›¸åŒçš„ï¼Œé€‚ç”¨äºï¼š

- ä»… CPU è®¾ç½®
- å• GPU è®¾ç½®
- å¤š GPU çš„åˆ†å¸ƒå¼è®­ç»ƒï¼ˆå•èŠ‚ç‚¹æˆ–å¤šèŠ‚ç‚¹ï¼‰
- TPU ä¸Šçš„è®­ç»ƒ

è¯·æ³¨æ„ï¼Œæ­¤åº“å¤„äº alpha å‘å¸ƒé˜¶æ®µï¼Œå› æ­¤å¦‚æœæ‚¨åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿æä¾›åé¦ˆã€‚